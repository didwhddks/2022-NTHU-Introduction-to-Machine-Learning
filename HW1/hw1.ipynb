{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "RzCR7vk9BFkf",
        "jnWjrzi0dMPz",
        "rUoRFoQjBW5S"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **HW1: Regression** \n",
        "In *assignment 1*, you need to finish:\n",
        "\n",
        "1.  Basic Part: Implement the regression model to predict the number of dengue cases\n",
        "\n",
        "\n",
        "> *   Step 1: Split Data\n",
        "> *   Step 2: Preprocess Data\n",
        "> *   Step 3: Implement Regression\n",
        "> *   Step 4: Make Prediction\n",
        "> *   Step 5: Train Model and Generate Result\n",
        "\n",
        "2.  Advanced Part: Implementing a regression model to predict the number of dengue cases in a different way than the basic part"
      ],
      "metadata": {
        "id": "X_Te27fi-0pP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Basic Part (60%)\n",
        "In the first part, you need to implement the regression to predict the number of dengue cases\n",
        "\n",
        "Please save the prediction result in a csv file **hw1_basic.csv**\n"
      ],
      "metadata": {
        "id": "_wDdnos-4uUv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Packages\n",
        "\n",
        "> Note: You **cannot** import any other package in the basic part"
      ],
      "metadata": {
        "id": "RzCR7vk9BFkf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import csv\n",
        "import math\n",
        "import random"
      ],
      "metadata": {
        "id": "HL5XjqFf4wSj"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Global attributes\n",
        "Define the global attributes"
      ],
      "metadata": {
        "id": "jnWjrzi0dMPz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_dataroot = 'hw1_basic_input.csv' # Input file named as 'hw1_basic_input.csv'\n",
        "output_dataroot = 'hw1_basic.csv' # Output file will be named as 'hw1_basic.csv'\n",
        "\n",
        "input_datalist =  [] # Initial datalist, saved as numpy array\n",
        "output_datalist =  [] # Your prediction, should be 10 * 4 matrix and saved as numpy array\n",
        "             # The format of each row should be ['epiweek', 'CityA', 'CityB', 'CityC']"
      ],
      "metadata": {
        "id": "EWLDPOlHBbcK"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can add your own global attributes here\n"
      ],
      "metadata": {
        "id": "PsFC-cvqIcYK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train = []\n",
        "validation = []\n",
        "test = []\n",
        "weights = []"
      ],
      "metadata": {
        "id": "OUbS2BEgcut6"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load the Input File\n",
        "First, load the basic input file **hw1_basic_input.csv**\n",
        "\n",
        "Input data would be stored in *input_datalist*"
      ],
      "metadata": {
        "id": "rUoRFoQjBW5S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read input csv to datalist\n",
        "input_datalist = pd.read_csv(input_dataroot)"
      ],
      "metadata": {
        "id": "dekR1KnqBtI6"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implement the Regression Model\n",
        "\n",
        "> Note: It is recommended to use the functions we defined, you can also define your own functions\n"
      ],
      "metadata": {
        "id": "6kYPuikLCFx4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 1: Split Data\n",
        "Split data in *input_datalist* into training dataset and validation dataset \n",
        "\n"
      ],
      "metadata": {
        "id": "jWwdx06JNEYs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def SplitData():\n",
        "  global train, validation, test\n",
        "  train = input_datalist[50:int(94*0.9)]\n",
        "  validation = input_datalist[int(94*0.9):94]\n",
        "  test = input_datalist[94:]"
      ],
      "metadata": {
        "id": "USDciENcB-5F"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 2: Preprocess Data\n",
        "Handle the unreasonable data\n",
        "> Hint: Outlier and missing data can be handled by removing the data or adding the values with the help of statistics  "
      ],
      "metadata": {
        "id": "u-3Qln4aNgVy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def HandleOutliers(dataset, kind):\n",
        "  # IQR method\n",
        "  iqr = dataset[kind].quantile(0.75) - dataset[kind].quantile(0.25)\n",
        "  lb = dataset[kind].quantile(0.25) - iqr*1.5\n",
        "  ub = dataset[kind].quantile(0.75) + iqr*1.5\n",
        "  dataset.loc[dataset[kind] >= ub, kind] = ub\n",
        "  dataset.loc[dataset[kind] <= lb, kind] = lb\n",
        "  return dataset\n",
        "\n",
        "def PreprocessData(dataset):\n",
        "  # Removing the missing data\n",
        "  dataset = dataset.dropna(how=\"any\")\n",
        "  # Handling the outliers\n",
        "  for i in dataset: \n",
        "    if i != 'epiweek':\n",
        "      dataset = HandleOutliers(dataset, i)\n",
        "  return dataset"
      ],
      "metadata": {
        "id": "XXvW1n_5NkQ5"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 3: Implement Regression\n",
        "> Hint: You can use Matrix Inversion, or Gradient Descent to finish this part\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "yDLpJmQUN3V6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Regression(xdata, ydata, degree):\n",
        "  # Matrix inversion\n",
        "  weights = []\n",
        "  A = []\n",
        "  B = []\n",
        "  for i in range(degree+1):\n",
        "    row = []\n",
        "    for j in range(degree+1):\n",
        "      row.append(np.sum([x**(i+j) for x in xdata]))\n",
        "    A.append(row)\n",
        "    B.append(np.sum(np.multiply([x**i for x in xdata], ydata)))\n",
        "  weights = np.matmul(np.linalg.inv(A), np.transpose(B))\n",
        "  return weights"
      ],
      "metadata": {
        "id": "Tx9n1_23N8C0"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 4: Make Prediction\n",
        "Make prediction of testing dataset and store the value in *output_datalist*"
      ],
      "metadata": {
        "id": "2NxRNFwyN8xd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def MAPE_calc(ydata, ypred):\n",
        "  s = 0\n",
        "  for i in range(len(ydata)):\n",
        "    s += abs(ydata[i]-ypred[i])/ydata[i]\n",
        "  return s*100/len(ydata)\n",
        "\n",
        "def MakePrediction():\n",
        "  global weights, train, validation, test\n",
        "  prediction = []\n",
        "  for i in range(len(weights)):\n",
        "    temp = []\n",
        "    for x in test.iloc[:,i+1:i+2].values:\n",
        "      temp.append(int(np.sum([w*x**j for j, w in enumerate(weights[i])])))\n",
        "    prediction.append(temp)\n",
        "    #print(MAPE_calc(validation.iloc[:,i+4:i+5].values, temp))\n",
        "    #print(temp)\n",
        "  return prediction"
      ],
      "metadata": {
        "id": "EKlDIC2-N_lk"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 5: Train Model and Generate Result\n",
        "\n",
        "> Notice: **Remember to output the coefficients of the model here**, otherwise 5 points would be deducted\n",
        "* If your regression model is *3x^2 + 2x^1 + 1*, your output would be: \n",
        "```\n",
        "3 2 1\n",
        "```\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "cCd0Z6izOCwq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SplitData()\n",
        "train = PreprocessData(train)\n",
        "validation = PreprocessData(validation)\n",
        "\n",
        "CityA_train_xdata = train.iloc[:,1:2].values\n",
        "CityA_train_ydata = train.iloc[:,4:5].values\n",
        "CityB_train_xdata = train.iloc[:,2:3].values\n",
        "CityB_train_ydata = train.iloc[:,5:6].values\n",
        "CityC_train_xdata = train.iloc[:,3:4].values\n",
        "CityC_train_ydata = train.iloc[:,6:7].values\n",
        "\n",
        "weights.append(Regression(CityA_train_xdata, CityA_train_ydata, 4)) # CityA\n",
        "weights.append(Regression(CityB_train_xdata, CityB_train_ydata, 3)) # CityB\n",
        "weights.append(Regression(CityC_train_xdata, CityC_train_ydata, 2)) # CityC\n",
        "\n",
        "output_datalist.append(test['epiweek'].values)\n",
        "pred = MakePrediction()\n",
        "for i in range(len(pred)):\n",
        "  output_datalist.append(pred[i])\n",
        "output_datalist = np.transpose(output_datalist)"
      ],
      "metadata": {
        "id": "iCL92EPKOFIn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "863252d8-8a3c-4bab-ea0e-60bd0b493fa6"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py:1817: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self._setitem_single_column(loc, value, pi)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Output the coefficients of the models\n",
        "for i in range(len(weights)):\n",
        "  print(\"Coefficients of Regression Model for City\", chr(i+65), \": \")\n",
        "  for j in range(len(weights[i])-1, -1, -1):\n",
        "    if j == 0:\n",
        "      print(weights[i][j])\n",
        "    else:\n",
        "      print(weights[i][j], end=', ')\n",
        "  print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_U9-k2vLt5Q",
        "outputId": "8f5edb9b-1bbc-47cb-aa3d-c775dc7099c4"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coefficients of Regression Model for City A : \n",
            "0.007982119326698012, -0.7125281058251858, 22.512685418128967, -289.6496422290802, 1229.2750129699707\n",
            "\n",
            "Coefficients of Regression Model for City B : \n",
            "-0.11077442114037694, 7.458440331276506, -166.8636347129941, 1262.573723912239\n",
            "\n",
            "Coefficients of Regression Model for City C : \n",
            "0.22522304691960926, -14.877287703982574, 274.34064501895045\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Write the Output File\n",
        "Write the prediction to output csv\n",
        "> Format: 'epiweek', 'CityA', 'CityB', 'CityC'"
      ],
      "metadata": {
        "id": "J8Jhd8wAOk3D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(output_dataroot, 'w', newline='', encoding=\"utf-8\") as csvfile:\n",
        "  writer = csv.writer(csvfile)\n",
        "  for row in output_datalist:\n",
        "    writer.writerow(row)"
      ],
      "metadata": {
        "id": "tYQVYLlKOtDB"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Advanced Part (35%)\n",
        "In the second part, you need to implement the regression in a different way than the basic part to help your predictions for the number of dengue cases\n",
        "\n",
        "We provide you with two files **hw1_advanced_input1.csv** and **hw1_advanced_input2.csv** that can help you in this part\n",
        "\n",
        "Please save the prediction result in a csv file **hw1_advanced.csv** \n"
      ],
      "metadata": {
        "id": "rx4408qg4xMQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Use temperature and precipitation\n",
        "basic_input_datalist = pd.read_csv(input_dataroot)\n",
        "advanced_input_datalist = pd.read_csv(\"hw1_advanced_input1.csv\")\n",
        "advanced_input_datalist = advanced_input_datalist.drop(\"epiweek\", axis=1)\n",
        "advanced_output_datalist = []\n",
        "\n",
        "# Combine two dataframes\n",
        "datalist = pd.concat([basic_input_datalist, advanced_input_datalist], axis=1)\n",
        "\n",
        "# Split and preprocess the data\n",
        "advanced_train = datalist[50:int(94*0.9)]\n",
        "advanced_validation = datalist[int(94*0.9):94]\n",
        "advanced_test = datalist[94:]\n",
        "\n",
        "advanced_train = PreprocessData(advanced_train)\n",
        "advanced_validation = PreprocessData(advanced_validation)\n",
        "\n",
        "# Data for CityA\n",
        "CityA_train_xdata = advanced_train[['TemperatureA', 'PrecipitationA']].values\n",
        "CityA_train_ydata = advanced_train['CityA'].values\n",
        "CityA_validation_xdata = advanced_validation[['TemperatureA', 'PrecipitationA']].values\n",
        "CityA_validation_ydata = advanced_validation['CityA'].values\n",
        "CityA_test_xdata = advanced_test[['TemperatureA', 'PrecipitationA']].values\n",
        "\n",
        "# Data for CityB\n",
        "CityB_train_xdata = advanced_train[['TemperatureB', 'PrecipitationB']].values\n",
        "CityB_train_ydata = advanced_train['CityB'].values\n",
        "CityB_validation_xdata = advanced_validation[['TemperatureB', 'PrecipitationB']].values\n",
        "CityB_validation_ydata = advanced_validation['CityB'].values\n",
        "CityB_test_xdata = advanced_test[['TemperatureB', 'PrecipitationB']].values\n",
        "\n",
        "# Data for CityC\n",
        "CityC_train_xdata = advanced_train[['TemperatureC', 'PrecipitationC']].values\n",
        "CityC_train_ydata = advanced_train['CityC'].values\n",
        "CityC_validation_xdata = advanced_validation[['TemperatureC', 'PrecipitationC']].values\n",
        "CityC_validation_ydata = advanced_validation['CityC'].values\n",
        "CityC_test_xdata = advanced_test[['TemperatureC', 'PrecipitationC']].values\n",
        "\n",
        "# Train the regression model and make prediction\n",
        "advanced_prediction = []\n",
        "advanced_prediction.append(LinearRegression().fit(CityA_train_xdata, CityA_train_ydata).predict(CityA_test_xdata))\n",
        "advanced_prediction.append(LinearRegression().fit(CityB_train_xdata, CityB_train_ydata).predict(CityB_test_xdata))\n",
        "advanced_prediction.append(LinearRegression().fit(CityC_train_xdata, CityC_train_ydata).predict(CityC_test_xdata))\n",
        "\n",
        "# Load data into output_datalist\n",
        "advanced_output_datalist.append(advanced_test['epiweek'].values)\n",
        "for i in range(len(advanced_prediction)):\n",
        "  advanced_output_datalist.append(advanced_prediction[i])\n",
        "advanced_output_datalist = np.transpose(advanced_output_datalist)\n",
        "\n",
        "# Load data to csv file\n",
        "with open(\"hw1_advanced.csv\", 'w', newline='', encoding=\"utf-8\") as csvfile:\n",
        "  writer = csv.writer(csvfile)\n",
        "  for row in advanced_output_datalist:\n",
        "    writer.writerow(row)"
      ],
      "metadata": {
        "id": "DaZCe19m41g1"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Report *(5%)*\n",
        "\n",
        "Report should be submitted as a pdf file **hw1_report.pdf**\n",
        "\n",
        "*   Briefly describe the difficulty you encountered \n",
        "*   Summarize your work and your reflections \n",
        "*   No more than one page\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "EtgCJU7FPeJL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save the Code File\n",
        "Please save your code and submit it as an ipynb file! (**hw1.ipynb**)"
      ],
      "metadata": {
        "id": "hlEE53_MPf4W"
      }
    }
  ]
}