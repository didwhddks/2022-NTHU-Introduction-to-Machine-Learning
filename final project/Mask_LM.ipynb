{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8d9f6f3",
   "metadata": {},
   "source": [
    "## WSD using BERT Masked Language Model\n",
    "This notebook explores the a part of the idea proposed by Ajit Rakasekharan in his blog post \n",
    "[Examining BERT raw embeddings.](https://towardsdatascience.com/examining-berts-raw-embeddings-fd905cb22df7) \n",
    "\n",
    "The idea is that examining the predictions of a masked language model for a masked ambiguous word can yield insights into the semantic meaning of the ambiguous word.\n",
    "\n",
    "We use the HuggingFace BERT for Masked LM with weights from a bert-base-cased pre-trained model for our experiment.\n",
    "\n",
    "We mask the ambiguous word (here we have used bank for our test) in sentences, and then send them through a BERT MLM model. Output is an array of logits for each position of the input sequence. So assuming a sentence with T tokens and a vocabulary size of V, the predictions of the MLM is (1, T, V) where 1 is the batch size (1 input sentence at a time in our experiment).\n",
    "\n",
    "In order to find the top k predictions, the logits for the masked position is softmaxed and the top k values chosen.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef418b6",
   "metadata": {},
   "source": [
    "## Prepare your environment\n",
    "\n",
    "As always, we highly recommend that you install all packages with a virtual environment manager, like [venv](https://packaging.python.org/en/latest/guides/installing-using-pip-and-virtual-environments/) or [conda](https://docs.conda.io/projects/conda/en/latest/user-guide/getting-started.html), to prevent version conflicts of different packages.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c35f05d0",
   "metadata": {},
   "source": [
    "### Masked LM Model and Tokenizer \n",
    "[tutorial](https://huggingface.co/docs/transformers/tasks/language_modeling)  \n",
    "Task is to predict words that are masked using BERT, so we will use BERTMaskedLM model and BERTTokenizer and use the pre-trained bert-base-uncased model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c548bc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\andre\\anaconda3\\envs\\NLP\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertForMaskedLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9ddf0c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
    "model = BertForMaskedLM.from_pretrained('bert-base-cased', return_dict=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58bb19fe",
   "metadata": {},
   "source": [
    "We are going to use the pre-trained BERT language model in inference mode only.\n",
    "\n",
    "The tokenizer tokenizes the input sequence and pads it with the [CLS] and [SEP] tokens.\n",
    "\n",
    "The output produced by the model has two components, loss and logits. The logits component has shape (1, number_of_tokens, vocab_size) where the leading 1 represents the single input sentence.\n",
    "\n",
    "We will identify the logits corresponding to the position of our masked token, identify the top 5 vocabulary words predicted for that position, and return the softmax probabilities for each of the top 5 predicted words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88d39fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(\"The capital of France is [MASK].\", return_tensors=\"pt\")\n",
    "outputs = model(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f0553c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]', 'The', 'capital', 'of', 'France', 'is', '[MASK]', '.', '[SEP]']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_ids_to_tokens(inputs.input_ids[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e6db335",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MaskedLMOutput(loss=None, logits=tensor([[[ -7.1545,  -6.9931,  -7.1826,  ...,  -5.9124,  -5.6733,  -5.9854],\n",
       "         [ -8.0190,  -8.1319,  -8.0509,  ...,  -6.5679,  -6.4058,  -6.8998],\n",
       "         [ -4.9772,  -6.1781,  -6.0669,  ...,  -5.6362,  -4.6603,  -5.1241],\n",
       "         ...,\n",
       "         [ -3.4420,  -3.2557,  -3.5733,  ...,  -2.4606,  -2.6495,  -3.1952],\n",
       "         [-10.5890, -10.4620, -11.7181,  ...,  -7.4646,  -9.9542,  -8.3927],\n",
       "         [-14.8900, -14.8873, -14.4569,  ..., -11.6588, -13.0151, -11.6073]]],\n",
       "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0433441f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_mask_index(input_ids, tokenizer):\n",
    "    x = input_ids[0]\n",
    "    is_masked = torch.where(x == tokenizer.mask_token_id, x, 0)\n",
    "    mask_idx = torch.nonzero(is_masked)\n",
    "    return mask_idx.item()\n",
    "\n",
    "mask_idx = get_mask_index(inputs.input_ids, tokenizer)\n",
    "mask_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5192f8b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Paris', 44.46825087070465),\n",
       " ('Lyon', 9.396003931760788),\n",
       " ('Toulouse', 8.234518766403198),\n",
       " ('Lille', 7.515139877796173),\n",
       " ('Marseille', 5.692288279533386)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_top_k_predictions(pred_logits, mask_idx, top_k):\n",
    "    probs = torch.nn.functional.softmax(pred_logits[0, mask_idx, :], dim=-1)\n",
    "    top_k_weights, top_k_indices = torch.topk(probs, top_k, sorted=True)\n",
    "    top_k_pct_weights = [100 * x.item() for x in top_k_weights]\n",
    "    top_k_tokens = tokenizer.convert_ids_to_tokens(top_k_indices)\n",
    "    return list(zip(top_k_tokens, top_k_pct_weights))\n",
    "\n",
    "\n",
    "get_top_k_predictions(outputs.logits, mask_idx, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b101bd3",
   "metadata": {},
   "source": [
    "### WSD Test Sentences\n",
    "We take our pair of sentences for disambiguating the word bank and mask them, and extract the top 20 predictions from the pre-trained BERT MLM model.\n",
    "\n",
    "As expected, the first set of predictions predominantly point to some sort of financial institution, whereas the second set of predictions predominantly point to some geographical formation around bodies of water."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d178f39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "  \"Go to the [MASK] and deposit your pay check.\",\n",
    "  \"Jim and Janet went down to the river [MASK] to admire the swans.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f00b91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(sentence, tokenizer, model):\n",
    "    inputs = tokenizer(sentence, return_tensors=\"pt\")\n",
    "    outputs = model(**inputs)\n",
    "    mask_idx = get_mask_index(inputs.input_ids, tokenizer)\n",
    "    top_preds = get_top_k_predictions(outputs.logits, mask_idx, 20)\n",
    "    return top_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "16805928",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('bank', 70.31391263008118),\n",
       " ('office', 10.280615836381912),\n",
       " ('register', 1.7452005296945572),\n",
       " ('store', 1.6284782439470291),\n",
       " ('bathroom', 0.9394792839884758),\n",
       " ('library', 0.8934846147894859),\n",
       " ('desk', 0.8724375627934933),\n",
       " ('counter', 0.7977348752319813),\n",
       " ('hotel', 0.5163734778761864),\n",
       " ('lobby', 0.49569723196327686),\n",
       " ('kitchen', 0.3637079382315278),\n",
       " ('garage', 0.34799312707036734),\n",
       " ('door', 0.34127470571547747),\n",
       " ('car', 0.3311377251520753),\n",
       " ('house', 0.2649053931236267),\n",
       " ('airport', 0.2547033363953233),\n",
       " ('elevator', 0.24911393411457539),\n",
       " ('back', 0.24807692971080542),\n",
       " ('computer', 0.24019642733037472),\n",
       " ('banks', 0.23491440806537867)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_predictions(sentences[0], tokenizer, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b2c01c47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('##bank', 32.602137327194214),\n",
       " ('below', 13.03199678659439),\n",
       " ('bank', 11.940894275903702),\n",
       " (',', 5.626494437456131),\n",
       " ('##boat', 3.1638894230127335),\n",
       " ('##front', 2.7332261204719543),\n",
       " ('basin', 1.621054857969284),\n",
       " ('##bed', 1.2178409844636917),\n",
       " ('together', 1.184169389307499),\n",
       " ('bed', 0.9657169692218304),\n",
       " ('again', 0.8369819261133671),\n",
       " ('deck', 0.8356173522770405),\n",
       " ('valley', 0.7271395064890385),\n",
       " ('mouth', 0.7227548863738775),\n",
       " ('boat', 0.7151047699153423),\n",
       " ('pier', 0.6493300199508667),\n",
       " ('house', 0.6301576271653175),\n",
       " ('banks', 0.5700556561350822),\n",
       " ('pool', 0.5345691461116076),\n",
       " ('Thames', 0.49955458380281925)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_predictions(sentences[1], tokenizer, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a23034",
   "metadata": {},
   "source": [
    "## Assignment\n",
    "In this week's assignment, you are tasked with processing SemCor data and feed the data into BERT masked-LM. After that, use the predictions to find the most likely sense of the target word using WordNet similarity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5627e5",
   "metadata": {},
   "source": [
    "### Data Preprocessing \n",
    "You can find a sample of SemCor dataset [here](https://drive.google.com/file/d/1inmv3rUcGrtiS4VQwTMsT9HF-iL8jc5V/view?usp=sharing) and load the data using the following methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "099c2d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet as wn\n",
    "sents = []\n",
    "tokens = []\n",
    "wn_id = []\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "with open('semcor.sample.jsonl') as f:\n",
    "    for line in f:\n",
    "        data = json.loads(line)\n",
    "        sents.append(data['sent'])\n",
    "        tokens.append(data['tokens'])\n",
    "        wn_id.append(data['wnid'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aa495af3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "implementation of georgia 's automobile title law was also recommended by the outgoing jury . \n",
      "['implementation', 'of', 'georgia', \"'s\", 'automobile', 'title', 'law', 'was', 'also', 'recommended', 'by', 'the', 'outgoing', 'jury', '.']\n",
      "['implementation%1:04:01::', 0, 'georgia%1:15:00::', 0, 'automobile%1:06:00::', 'title%1:10:04::', 'law%1:10:00::', 0, 'also%4:02:00::', 'recommend%2:32:01::', 0, 0, 'outgoing%3:00:00::', 'jury%1:14:00::', 0]\n"
     ]
    }
   ],
   "source": [
    "print(sents[10])\n",
    "print(tokens[10])\n",
    "print(wn_id[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "14229b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The WordNet ID can be converted to NLTK Lemma using the following function\n",
    "# nltk.download('wordnet')\n",
    "# nltk.download('omw-1.4')\n",
    "L = wn.lemma_from_key('implementation%1:04:01::')\n",
    "# print(L.synset())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "48e468bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Synset('execution.n.06'), Synset('implementation.n.02')]\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(wn.synsets('implementation'))\n",
    "print(len(wn.synsets('.')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fac4dbe",
   "metadata": {},
   "source": [
    "### TODO \n",
    "Please implement a method to convert the data to BERT Masked-LM format and keep track of the headword. Store the data into the following lists\n",
    "\n",
    "word[i] = 'implementation'  \n",
    "ground_truth[i] = 'implementation%1:04:01::'  \n",
    "sent[i] = \"[MASK] of georgia 's automobile title law was also recommended by the outgoing jury .\"  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "162db185",
   "metadata": {},
   "outputs": [],
   "source": [
    "word = []\n",
    "ground_truth = []\n",
    "sent = []\n",
    "sen_id = 0\n",
    "while(sen_id < 100):\n",
    "    for i in range(len(tokens[sen_id])):\n",
    "        if(wn_id[sen_id][i]):\n",
    "            sent.append(sents[sen_id].replace(tokens[sen_id][i], \"[MASK]\",1))\n",
    "            word.append(tokens[sen_id][i])\n",
    "            ground_truth.append(wn_id[sen_id][i])\n",
    "        if(i == len(tokens[sen_id])-1):\n",
    "            sen_id += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e011450",
   "metadata": {},
   "source": [
    "#### Identify the top 5 predictions other than the headword using Masked-LM \n",
    "1. Use get_predictions to get the predicted words\n",
    "2. Use lemmatizer to lemmatize the prediction\n",
    "3. Remove headword\n",
    "4. Keep top 5 unique predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8b94c14d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1042/1042 [01:09<00:00, 15.04it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "no_processed_candidate_lemmas = []\n",
    "for sen in tqdm(sent):\n",
    "    try:\n",
    "        no_processed_candidate_lemmas.append(get_predictions(sen, tokenizer, model))\n",
    "    except:\n",
    "        print(sen)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b79a3c9",
   "metadata": {},
   "source": [
    "example:  \n",
    "candidate_lemmas = ['office', 'register', 'store', 'bathroom', 'library']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4bf3a95",
   "metadata": {},
   "source": [
    "Identify the most similar sense of headword with relation to the 5 unique candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "30c0dab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1042/1042 [00:16<00:00, 62.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size\n",
      "Lemma('size.n.01.size')\n",
      "\" only a relative handful of such reports was received \" , the jury said , \" considering the widespread interest in the election , the number of voters and the [MASK] of_this city \" . \n",
      "['population', 'status', 'reputation', 'character', 'state']\n",
      "Synset('size.n.04')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "candidate_lemmas = []\n",
    "lm = WordNetLemmatizer()\n",
    "for i in range(len(no_processed_candidate_lemmas[:])):\n",
    "    #print(no_processed_candidate_lemmas[i][0][0])\n",
    "    # k = 0\n",
    "    tem_candidates = []\n",
    "    for tup in no_processed_candidate_lemmas[i]:\n",
    "        k = 0\n",
    "        to_compare = lm.lemmatize(tup[0])\n",
    "        if to_compare != lm.lemmatize(word[i]) and to_compare not in tem_candidates and len(wn.synsets(to_compare))>0:\n",
    "            if len(tem_candidates) < 5:\n",
    "                tem_candidates.append(to_compare)\n",
    "                # k += 1\n",
    "                # print(len(tem_candidates))\n",
    "            else: \n",
    "                break\n",
    "    candidate_lemmas.append(tem_candidates)\n",
    "\n",
    "\n",
    "predicted_sense = []\n",
    "# total_len = 0\n",
    "for i in tqdm(range(len(word))):\n",
    "    headword = lm.lemmatize(word[i])\n",
    "    synset_list = wn.synsets(headword)\n",
    "    # similarity = 0\n",
    "    if len(synset_list) == 0:\n",
    "        predicted_sense.append(0)\n",
    "        continue\n",
    "    # total_len += len(synset_list)\n",
    "    # print(len(synset_list))\n",
    "    # tem_ans_syn = synset_list[0]\n",
    "    vote = [0]*len(synset_list)\n",
    "    for similar_word in candidate_lemmas[i]:\n",
    "        tem_similar = [0]*len(synset_list)\n",
    "        k = 0\n",
    "        for syn in synset_list:\n",
    "            similar_synset = wn.synsets(similar_word)\n",
    "            similarity = 0\n",
    "            for similar_syn in similar_synset:\n",
    "                if wn.path_similarity(syn, similar_syn) > similarity:\n",
    "                    similarity = wn.path_similarity(syn, similar_syn)\n",
    "                    tem_ans_syn = syn\n",
    "            tem_similar[k] = similarity\n",
    "            k += 1\n",
    "        vote[tem_similar.index(max(tem_similar))] += 1\n",
    "    # if headword == 'size':\n",
    "    #     print(vote)\n",
    "    #     print(synset_list)\n",
    "    predicted_sense.append(synset_list[vote.index(max(vote))])\n",
    "    # predicted_sense.append(tem_ans_syn)\n",
    "\n",
    "\n",
    "print(word[50])\n",
    "print(wn.lemma_from_key(ground_truth[50]))\n",
    "print(sent[50])\n",
    "print(candidate_lemmas[50])\n",
    "print(predicted_sense[50])\n",
    "# print(total_len/len(word))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac3cf473",
   "metadata": {},
   "source": [
    "For evaluation purpose, for i = 50, please run the process and print out the following:  \n",
    "1. word[50]\n",
    "2. ground_truth[50] (in synset or lemma)\n",
    "3. sent[50]\n",
    "4. candidate_lemmas\n",
    "5. predicted_sense (in synset or lemma)    \n",
    "\n",
    "Also, please print out the accuracy of the process over our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "28c3dfe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.46417445482866043\n"
     ]
    }
   ],
   "source": [
    "score = 0\n",
    "wrong_case = 0\n",
    "#print(wn.path_similarity(wn.synset('primary.a.01'), wn.synset('primary.n.01')))\n",
    "for i in range(len(predicted_sense)):\n",
    "    try:\n",
    "        #print(ans_syn[i] ,wn.lemma_from_key(ground_truth[i]).synset(), end=\"\")\n",
    "        if predicted_sense[i] == wn.lemma_from_key(ground_truth[i]).synset():\n",
    "            score += 1\n",
    "            #print(True)\n",
    "        else:\n",
    "            #print(False)\n",
    "            pass\n",
    "    except:\n",
    "        #print(ground_truth[i], ans_syn[i])\n",
    "        wrong_case += 1\n",
    "# print(score)\n",
    "accuracy = score/(len(predicted_sense)-wrong_case)\n",
    "print(\"accuracy: \", accuracy)\n",
    "# print(wn.lemma_from_key(\"recent%3:00:00:00:\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1225036f",
   "metadata": {},
   "source": [
    "## TA's Note\n",
    "\n",
    "Congratulations, you made it to the end of the tutorial! Make sure you make an appointment to show your work and turn in your finished assignment before next week's lesson. We will ask you to run your code, so double check that everything is working and that your model is saved. Don't worry if you didn't pass the evaluation requirements, you'll still get partial points for trying."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01435bc9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('NLP')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "6830b98b739c8b178140b3b99500fc284e3d796c4b91cec6d49e826d769bcf39"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
